{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap matrix correlation between price and variables in every region in Belgium\n",
    "We are analyzing property data in Belgium and generating correlation heatmaps for different property types.\n",
    "## Step 1: Import Required Libraries\n",
    "We begin by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data\n",
    "Next, we load the property data from a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"property_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning\n",
    "3.1. Removing Duplicates\n",
    "\n",
    "To ensure each data point is unique, we remove duplicate entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Removing Leading and Trailing Spaces\n",
    "To maintain data consistency, we strip leading and trailing spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Filling Missing Values\n",
    "We replace missing values in numeric columns with '0' and in non-numeric columns with 'unknown':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.dtypes == np.float64] = df.loc[:, df.dtypes == np.float64].fillna(0)\n",
    "df.loc[:, df.dtypes == np.int64] = df.loc[:, df.dtypes == np.int64].fillna(0)\n",
    "df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Processing\n",
    "4.1. Ensure Correct Data Types\n",
    "We convert specific columns into appropriate data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip code'] = df['Zip code'].astype(int)\n",
    "df['Subtype of property'] = df['Subtype of property'].astype(str)\n",
    "df['Type of Sale'] = df['Type of Sale'].astype(str)\n",
    "df['State of the building'] = df['State of the building'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. One-Hot Encoding\n",
    "\n",
    "We perform one-hot encoding on categorical variables, resulting in binary columns for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['Subtype of property', 'Type of Sale', 'State of the building'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Data Analysis\n",
    "We group the data by 'Type of property' and conduct an analysis for each group. We skip the groups where type_of_property is '0' or 'unknown'. Depending on the type of property ('apartment' or other), we select a different set of numeric columns. We then calculate a correlation matrix for these numeric columns and visualize this matrix using a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Region'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Calculate the correlation matrix of the numeric columns within each region and type of property\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m (region, type_of_property), group_df \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mRegion\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mType of property\u001b[39;49m\u001b[39m'\u001b[39;49m]):\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRegion: \u001b[39m\u001b[39m{\u001b[39;00mregion\u001b[39m}\u001b[39;00m\u001b[39m, Type of property: \u001b[39m\u001b[39m{\u001b[39;00mtype_of_property\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Use a different set of numeric columns for apartments and houses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tsepu\\Documents\\GitHub\\challenge-data-analysis\\data_visualization_env\\Lib\\site-packages\\pandas\\core\\frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8262\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tsepu\\Documents\\GitHub\\challenge-data-analysis\\data_visualization_env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[0;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    932\u001b[0m         obj,\n\u001b[0;32m    933\u001b[0m         keys,\n\u001b[0;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    939\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\tsepu\\Documents\\GitHub\\challenge-data-analysis\\data_visualization_env\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Region'"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix of the numeric columns within each region and type of property\n",
    "for (region, type_of_property), group_df in df.groupby(['Region', 'Type of property']):\n",
    "    print(f\"Region: {region}, Type of property: {type_of_property}\")\n",
    "\n",
    "    # Use a different set of numeric columns for apartments and houses\n",
    "    if type_of_property == 'apartment':\n",
    "        numeric_cols = ['Price of property in euro', 'Kitchen', 'Number of bedrooms', 'Living area', 'Terrace area', 'Garden', 'Garden area', 'Number of facades']\n",
    "    else:\n",
    "        numeric_cols = ['Price of property in euro', 'Kitchen', 'Number of bedrooms', 'Living area', 'Terrace area', 'Garden', 'Garden area', 'Surface of the land(or plot of land)', 'Number of facades', 'Swimming pool']\n",
    "    \n",
    "    corr = group_df[numeric_cols].corr()\n",
    "    fig = px.imshow(corr, title=f\"Correlation matrix of variables and price in {region} for {type_of_property}\", zmin=-1, zmax=1)\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_visualization_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
